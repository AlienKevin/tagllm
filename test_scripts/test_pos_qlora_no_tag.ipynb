{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce69b81e-1902-460b-809e-e83050cb6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq -U transformers datasets huggingface_hub accelerate bitsandbytes tqdm --progress-bar off\n",
    "!FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install -qqq -U flash-attn --no-build-isolation pip install flash-attn --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d8cbae-9484-4013-9cdd-4057653463f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760b51b774ad4aa7801774d3e13bfee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d821f3dc-9b0c-46ef-b916-273c13c36bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62f03ac49a04976ac4a7721a62f066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "# Set torch dtype and attention implementation\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n",
    "\n",
    "base_model = \"meta-llama/Meta-Llama-3-8B\"\n",
    "new_model = \"Meta-Llama-3-8B-qlora-pos-no-tag\"\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(base_model, padding_side='left')\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14563d80-8385-4d03-bc02-5a1d3bc4755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, features\n",
    "\n",
    "def patch_v(tag):\n",
    "    if tag == 'V':\n",
    "        return 'VERB'\n",
    "    else:\n",
    "        return tag\n",
    "\n",
    "def get_dataset(num_existing_tokens=0):\n",
    "    dataset = load_dataset(\"hkcancor\", \"default\")\n",
    "\n",
    "    single_lang = [\"eng\", \"yue\", \"cmn\"]\n",
    "\n",
    "    tag_name_dict = {}\n",
    "    for lang in single_lang:\n",
    "        tag_name_dict[lang] = f'{lang}:'\n",
    "\n",
    "    source_upos = dataset['train'].features[\"pos_tags_ud\"].feature\n",
    "    print(\"Source upos:\", source_upos)\n",
    "\n",
    "    def preprocess_function(example):\n",
    "        example[\"input\"] = 'input:' + ' '.join(example[\"tokens\"]) + \"\\n\" + \\\n",
    "            \"output:\" + ' '.join(patch_v(source_upos.int2str(tag)).lower()\n",
    "            for tag in example[\"pos_tags_ud\"])\n",
    "        return example\n",
    "    \n",
    "    dataset['train'] = dataset['train'].map(preprocess_function, remove_columns=\n",
    "        ['tokens', 'conversation_id', 'pos_tags_prf', 'pos_tags_ud', 'speaker', 'transcriptions', 'turn_number', 'tokens'])\n",
    "\n",
    "    dataset['train'] = dataset['train'].shuffle(42)\n",
    "    dataset['train'] = dataset['train'].select(range(10))\n",
    "    prompt = '\\n'.join(example['input'] for example in dataset['train'].take(10)) + '\\n'\n",
    "    print(prompt)\n",
    "    \n",
    "    dataset = load_dataset(\"universal_dependencies\", \"yue_hk\")\n",
    "    test_dataset = dataset[\"test\"]\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        examples[\"inputs\"] = [prompt + \"input:\" + ' '.join(examples[\"tokens\"][i]) + \"\\n\" + \"output:\" for i in range(len(examples[\"tokens\"]))]\n",
    "        return examples\n",
    "    \n",
    "    test_dataset = test_dataset.map(preprocess_function, remove_columns=\n",
    "        ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'], batched=True)\n",
    "\n",
    "    return prompt, test_dataset, tag_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639b897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source upos: ClassLabel(names=['NUM', 'ADP', 'INTJ', 'PROPN', 'ADJ', 'V', 'DET', 'ADV', 'CCONJ', 'PRON', 'X', 'PART', 'AUX', 'VERB', 'NOUN', 'PUNCT'], id=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad43c206420471a8c47bab458f4d934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10801 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:啲 - 啲 sales 嘅 質素 下降 ， 會 唔 會 好似 同 醫管局 嗰啲 …\n",
      "output:noun punct noun noun part noun verb punct aux adv aux verb adp propn pron punct\n",
      "input:唉 ， 有 乜嘢 辦法 啊 ， 興 吖 嗎 ， 咁 興 啊 。\n",
      "output:intj punct verb pron noun part punct verb part part punct adv verb part punct\n",
      "input:夠 嚹 。\n",
      "output:verb part punct\n",
      "input:噉 另外 就 同 佢 太太 之間 呢 亦都 有 個 中年 婚姻 危機 𡃉 。 即係 覺得 太太 ， 冇 理由 我 太太 會 重 - 重 愛 我 吖 。 即係 我 事業 又 唔 得 ， 要 樣 冇 樣 ， 要 錢 冇 錢 噉樣 。 噉 另外 有 個 黑人 嘅 。 就 係 鬍鬚 阿伯 ， 就 成 五十 歲 嘅 。 點解 會 揾 到 佢 ？ 因為 佢 要 揾 個 人 教 跳舞 吖 嗎 。 而 哩個 阿伯 係 識 跳 所有 爵士舞 ， 只不過 係 因為 骨頭 硬 。 即係 跳 起 身 ， 跌落 地下 之後 就 起 唔 到 身 𡃉 嘞 。 但係 之前 嗰 段 係 得 嘅 。\n",
      "output:cconj cconj adv adp pron noun adv part adv verb noun noun noun noun part punct cconj verb noun punct verb noun pron noun aux adv punct adv verb pron part punct cconj pron noun adv adv verb punct aux noun verb noun punct aux noun verb noun cconj punct cconj cconj verb noun noun part punct adv verb noun noun punct adv num num noun part punct pron aux verb part pron punct cconj pron aux verb noun noun verb verb part part punct cconj pron noun verb verb verb adj noun punct adv verb cconj noun adj punct cconj verb verb noun punct verb noun adv adv verb adv part noun part part punct cconj adv pron noun verb aux part punct\n",
      "input:噉 𠻺 係 。 自己 儲 郵票 嘅 ， 就 唔 會 噉 𡃉 喇 。\n",
      "output:pron adv verb punct pron verb noun part punct adv adv aux pron part part punct\n",
      "input:跟住 然之後 佢 話 ， Holly 呢 ， 另外 嗰個 friend 呢 去 咗 哈爾濱 旅行 啊 。\n",
      "output:cconj cconj pron verb punct propn part punct cconj pron noun part verb part propn verb part punct\n",
      "input:嗯 ， 我 都 估 到 佢 - 其實 我 都 估 到 佢 冇 去 考 𡃉 嚹 。\n",
      "output:intj punct pron adv verb part pron punct adv pron adv verb part pron verb adp verb part part punct\n",
      "input:喂 ， 但係 點解 你 要 特登 提 出來 ， 因為 我哋 唔係 教徒 哩樣 嘢 呢 ？ 所以 先至 相信 。\n",
      "output:intj punct cconj pron pron aux adv verb verb punct cconj pron verb noun pron noun part punct cconj adv verb punct\n",
      "input:真係 。\n",
      "output:adv punct\n",
      "input:噉 你 就 ， 誒 ， 點樣 - 即係 你 影印 咗 一萬 個 - 唔係 ， 一千 個 copy 啊 。\n",
      "output:cconj pron adv punct intj punct pron punct cconj pron verb part num noun punct verb punct num noun noun part punct\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d45d0b61aa743c8880157f96bbd013c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/143k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58770eadca4f444987e2db5f8ef76afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d9095225549f1ae7274c90d9ebd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt, eval_dataset, tag_name_dict = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecc95da-b9bd-40dc-acab-3aed3186b9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs'],\n",
       "    num_rows: 1004\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd1a9f7-8d17-4023-984c-0ce1a4bb0dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': ['input:啲 - 啲 sales 嘅 質素 下降 ， 會 唔 會 好似 同 醫管局 嗰啲 …\\noutput:noun punct noun noun part noun verb punct aux adv aux verb adp propn pron punct\\ninput:唉 ， 有 乜嘢 辦法 啊 ， 興 吖 嗎 ， 咁 興 啊 。\\noutput:intj punct verb pron noun part punct verb part part punct adv verb part punct\\ninput:夠 嚹 。\\noutput:verb part punct\\ninput:噉 另外 就 同 佢 太太 之間 呢 亦都 有 個 中年 婚姻 危機 𡃉 。 即係 覺得 太太 ， 冇 理由 我 太太 會 重 - 重 愛 我 吖 。 即係 我 事業 又 唔 得 ， 要 樣 冇 樣 ， 要 錢 冇 錢 噉樣 。 噉 另外 有 個 黑人 嘅 。 就 係 鬍鬚 阿伯 ， 就 成 五十 歲 嘅 。 點解 會 揾 到 佢 ？ 因為 佢 要 揾 個 人 教 跳舞 吖 嗎 。 而 哩個 阿伯 係 識 跳 所有 爵士舞 ， 只不過 係 因為 骨頭 硬 。 即係 跳 起 身 ， 跌落 地下 之後 就 起 唔 到 身 𡃉 嘞 。 但係 之前 嗰 段 係 得 嘅 。\\noutput:cconj cconj adv adp pron noun adv part adv verb noun noun noun noun part punct cconj verb noun punct verb noun pron noun aux adv punct adv verb pron part punct cconj pron noun adv adv verb punct aux noun verb noun punct aux noun verb noun cconj punct cconj cconj verb noun noun part punct adv verb noun noun punct adv num num noun part punct pron aux verb part pron punct cconj pron aux verb noun noun verb verb part part punct cconj pron noun verb verb verb adj noun punct adv verb cconj noun adj punct cconj verb verb noun punct verb noun adv adv verb adv part noun part part punct cconj adv pron noun verb aux part punct\\ninput:噉 𠻺 係 。 自己 儲 郵票 嘅 ， 就 唔 會 噉 𡃉 喇 。\\noutput:pron adv verb punct pron verb noun part punct adv adv aux pron part part punct\\ninput:跟住 然之後 佢 話 ， Holly 呢 ， 另外 嗰個 friend 呢 去 咗 哈爾濱 旅行 啊 。\\noutput:cconj cconj pron verb punct propn part punct cconj pron noun part verb part propn verb part punct\\ninput:嗯 ， 我 都 估 到 佢 - 其實 我 都 估 到 佢 冇 去 考 𡃉 嚹 。\\noutput:intj punct pron adv verb part pron punct adv pron adv verb part pron verb adp verb part part punct\\ninput:喂 ， 但係 點解 你 要 特登 提 出來 ， 因為 我哋 唔係 教徒 哩樣 嘢 呢 ？ 所以 先至 相信 。\\noutput:intj punct cconj pron pron aux adv verb verb punct cconj pron verb noun pron noun part punct cconj adv verb punct\\ninput:真係 。\\noutput:adv punct\\ninput:噉 你 就 ， 誒 ， 點樣 - 即係 你 影印 咗 一萬 個 - 唔係 ， 一千 個 copy 啊 。\\noutput:cconj pron adv punct intj punct pron punct cconj pron verb part num noun punct verb punct num noun noun part punct\\ninput:你 喺度 搵 乜嘢 呀 ？\\noutput:',\n",
       "  'input:啲 - 啲 sales 嘅 質素 下降 ， 會 唔 會 好似 同 醫管局 嗰啲 …\\noutput:noun punct noun noun part noun verb punct aux adv aux verb adp propn pron punct\\ninput:唉 ， 有 乜嘢 辦法 啊 ， 興 吖 嗎 ， 咁 興 啊 。\\noutput:intj punct verb pron noun part punct verb part part punct adv verb part punct\\ninput:夠 嚹 。\\noutput:verb part punct\\ninput:噉 另外 就 同 佢 太太 之間 呢 亦都 有 個 中年 婚姻 危機 𡃉 。 即係 覺得 太太 ， 冇 理由 我 太太 會 重 - 重 愛 我 吖 。 即係 我 事業 又 唔 得 ， 要 樣 冇 樣 ， 要 錢 冇 錢 噉樣 。 噉 另外 有 個 黑人 嘅 。 就 係 鬍鬚 阿伯 ， 就 成 五十 歲 嘅 。 點解 會 揾 到 佢 ？ 因為 佢 要 揾 個 人 教 跳舞 吖 嗎 。 而 哩個 阿伯 係 識 跳 所有 爵士舞 ， 只不過 係 因為 骨頭 硬 。 即係 跳 起 身 ， 跌落 地下 之後 就 起 唔 到 身 𡃉 嘞 。 但係 之前 嗰 段 係 得 嘅 。\\noutput:cconj cconj adv adp pron noun adv part adv verb noun noun noun noun part punct cconj verb noun punct verb noun pron noun aux adv punct adv verb pron part punct cconj pron noun adv adv verb punct aux noun verb noun punct aux noun verb noun cconj punct cconj cconj verb noun noun part punct adv verb noun noun punct adv num num noun part punct pron aux verb part pron punct cconj pron aux verb noun noun verb verb part part punct cconj pron noun verb verb verb adj noun punct adv verb cconj noun adj punct cconj verb verb noun punct verb noun adv adv verb adv part noun part part punct cconj adv pron noun verb aux part punct\\ninput:噉 𠻺 係 。 自己 儲 郵票 嘅 ， 就 唔 會 噉 𡃉 喇 。\\noutput:pron adv verb punct pron verb noun part punct adv adv aux pron part part punct\\ninput:跟住 然之後 佢 話 ， Holly 呢 ， 另外 嗰個 friend 呢 去 咗 哈爾濱 旅行 啊 。\\noutput:cconj cconj pron verb punct propn part punct cconj pron noun part verb part propn verb part punct\\ninput:嗯 ， 我 都 估 到 佢 - 其實 我 都 估 到 佢 冇 去 考 𡃉 嚹 。\\noutput:intj punct pron adv verb part pron punct adv pron adv verb part pron verb adp verb part part punct\\ninput:喂 ， 但係 點解 你 要 特登 提 出來 ， 因為 我哋 唔係 教徒 哩樣 嘢 呢 ？ 所以 先至 相信 。\\noutput:intj punct cconj pron pron aux adv verb verb punct cconj pron verb noun pron noun part punct cconj adv verb punct\\ninput:真係 。\\noutput:adv punct\\ninput:噉 你 就 ， 誒 ， 點樣 - 即係 你 影印 咗 一萬 個 - 唔係 ， 一千 個 copy 啊 。\\noutput:cconj pron adv punct intj punct pron punct cconj pron verb part num noun punct verb punct num noun noun part punct\\ninput:咪 執 返 啲 嘢 去 阿哥 個 新 屋 度 囖 。\\noutput:']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cccb0a-ee04-4667-858a-cf77bafd2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/PygmalionAI/pygmalion-6b/discussions/25#64387bf26c8841ba74e7d9c0\n",
    "from transformers import StoppingCriteria\n",
    "\n",
    "class TranslationStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, prompt):\n",
    "        self.prompt = prompt\n",
    "        \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Get the generated text as a string\n",
    "        generated_text = tokenizer.decode(input_ids[0])\n",
    "        generated_text = generated_text.removeprefix(prompt)\n",
    "        if generated_text.endswith('\\n'):\n",
    "            return True  # Stop generation\n",
    "        return False  # Continue generation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7ddec9-4a6e-484a-af2d-05b51b068553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [25:26<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "outputs = pipeline(\n",
    "    KeyDataset(eval_dataset, \"inputs\"),\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    stopping_criteria=TranslationStoppingCriteria(prompt),\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "def parse_translation(text):\n",
    "    lines = text.strip().split('\\n')\n",
    "    result = { 'langs': [], 'sents': [] }\n",
    "    \n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            lang, content = line.split(':', 1)\n",
    "            if lang in ['input', 'output']:\n",
    "                result['langs'].append('yue' if lang == 'input' else 'pos')\n",
    "                result['sents'].append(content.strip())\n",
    "    \n",
    "    return result\n",
    "\n",
    "with open(f'experiment_results/pos_{new_model}.jsonl', 'w+') as f:\n",
    "    for output in tqdm(outputs, total=len(eval_dataset)):\n",
    "        generated_text = output[0]['generated_text']\n",
    "        generated_text = generated_text.removeprefix(prompt)\n",
    "        f.write(json.dumps(parse_translation(generated_text)) + '\\n')\n",
    "        f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
